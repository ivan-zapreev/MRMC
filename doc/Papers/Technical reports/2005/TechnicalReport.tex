\documentclass[a4paper,10pt]{article}
\usepackage[T1]{fontenc}
\usepackage{ae,aecompl}
\usepackage{amssymb}
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage[dvips]{graphicx}
\usepackage{algorithm}
\usepackage{algorithmic}

% Title Page
\title{ETMCC v2.0}
\author{Joost-Pieter Katoen, Maneesh Khattri, Ivan S Zapreev}

\begin{document}
\maketitle

\newpage

\tableofcontents 

\newpage

\section{Introduction \textit{\{Joost-Pieter\}}}
	Aims, Challenges, etc.

\section{Stochastic model checking \textit{\{Joost-Pieter\}}}
	CSL, PCTL, PRCTL, CSRL

\section{Data Structures \textit{\{Maneesh, Ivan\}}}
	Compressed Column/Row format. Changes, Example. Reasons for changing structure.
	Comparison with the SparseLib++, Sparse 1.3.

\section{Algorithms implementation}

In this section the model-checking algorithms, in some detail, are presented.

	\subsection{Matrix-vector multiplication \textit{\{Maneesh\}}}
	In linear algebra, matrix-vector multiplication is one of the most important operations. Since
	the evaluation of most formulas in PCTL and CSL can be reduced to matrix-vector products
	hence it is important that this particular operation be made as efficient as is possible. The
	question of efficiency of matrix-vector multiplication can also be found in existing literature
	and, in particular, in the thesis \cite{ejim1}. Other numerical analysts have also considered this
	question and as a result have produced software systems for handling large sparse matrices. In this
	context, SparseLib++ and Sparse 1.3 seem to be the most important.
	
	Returning to the question of matrix-vector multiplications, it appears that most previous experiments
	have concentrated on making the vector accesses as close to each other as possible. It has been argued, that
	while the accesses to the matrix elements, for sparse matrices in CRS or CCS, are mostly in a linear fashion the
	accesses to the vector elements are more random in nature. The result of this, when executed on modern computers
	with many memory-levels, is that random accesses to very large vectors causes misses in faster memory requiring
	access to slower types of memory. To understand this further, consider the matrix-vector multiplication algorithm
	for the new data-structure cf. Algorithm \ref{alg:mvm}.
	
	\begin{algorithm}
	\caption{Matrix-vector multiplication}
	\label{alg:mvm}
	\begin{algorithmic}[1]
	\PROC{ MVM(matrix m, vector v) }
		\STATE $rows=m.rows;$ $array\ ncols=m.ncols;$ $init\ array\ result;$
		\FOR{$i=0\cdots rows$}
			\STATE $ncol=ncols[i];$ $res=m.diag[i]\cdot v[i];$
			\IF{ $ncol>0$ }
				\STATE $array\ col\_id=col[i];$ $array\ val=val[i];$
				\FOR{$j=0\cdots ncol$}
					\STATE $res=res+v[col\_id[j]]\cdot val[j]$
				\ENDFOR
			\ENDIF
			\STATE $result[i]=res$
		\ENDFOR
	\ENDPROC
	\end{algorithmic}
	\end{algorithm}
	
	Overview, theses etc ... What is incorporated.

\subsection{Search for BSCCs \textit{\{Ivan\}}}
	Tarjan's algorithms. Initial improvements by other people.
	improvements.

\subsection{Solving linear equations \textit{\{Ivan\}}}
	System, transposed-systems.
	
\subsection{PCTL \textit{\{Ivan\}}}
\subsection{Path Formulas + E,C,Y - PRCTL \textit{\{Maneesh\}}}
\subsection{Path Formulas - CSL \textit{\{Maneesh\}}}
In this section some well-known results for the transient analysis of Markov chains are presented. In most cases
the analysis is reduced to a matrix-vector product. In the sequel let
\begin{equation*}
\psi(i, \Lambda\cdot t) = \frac{e^{-\Lambda t}\cdot(\Lambda t)^{i}}{i!}.
\end{equation*}
be refered to as the Poisson probabilities. These are computed using the Fox \& Glynn algorithm \cite{fox1}.
	\subsubsection{Unbounded Ne$\mathcal{X}$t}
	The value of the unbounded Ne$\mathcal{X}$t operator can be obtained by the following matrix-vector product:
	\begin{equation*}
		Prob(\mathcal{X}\Phi) = \underline{P} \cdot \underline{1}_{\Phi}
	\end{equation*}
	where $\underline{P}(s,s^{\prime})=\frac{\underline{R}(s,s^{\prime})}{E(s)}$.
	\subsubsection{Bounded/Interval Ne$\mathcal{X}$t}
	The value of the bounded/interval Ne$\mathcal{X}$t operator can be obtained by the following matrix-vector product:
	\begin{equation*}
	Prob(\mathcal{X}^I\Phi) = (e^{-E(s) \cdot inf I}-e^{-E(s) \cdot sup I}) \cdot \underline{P} \cdot \underline{1}_{\Phi}
	\end{equation*}
	where $\underline{P}(s,s^{\prime})=\frac{\underline{R}(s,s^{\prime})}{E(s)}$.
	\subsubsection{Unbounded $\mathcal{U}$ntil - special cases}
	In this section the special case $\mathcal{P}_{>0}(\Phi \mathcal{U} \Psi)$ is considered.
	\begin{equation*}
		s\vDash\mathcal{P}_{>0}(\Phi \mathcal{U} \Psi) \Leftrightarrow Prob(\sigma \in Paths(s) \wedge \sigma \vDash (\Phi \mathcal{U} \Psi))>0 \Leftrightarrow s\vDash\exists(\Phi \mathcal{U} \Psi)
	\end{equation*}
	where $s\vDash\exists(\Phi \mathcal{U} \Psi)$ is obtained by fix-point iteration by a backward search starting from $SAT(\Psi)$
	\begin{equation*}
	s\vDash\exists(\Phi \mathcal{U} \Psi) \Leftrightarrow s\vDash (\Psi \vee (\Phi \wedge \mathcal{X}(\exists(\Phi \mathcal{U} \Psi))))
	\end{equation*}
	\subsubsection{Unbounded $\mathcal{U}$ntil - General}
	The value of the general unbounded $\mathcal{U}$ntil operator can be obtained by the least solution of the following set of linear equations:
	\begin{equation*}\underline{x} = P^{\prime} \cdot \underline{x} + \underline{1}_{\Psi}\end{equation*}
	where $\underline{P}^{\prime}(s,s^{\prime})=\underline{P}(s,s^{\prime})$ if $s\vDash(\Phi\wedge\lnot\Psi)$ and 0 otherwise.
	There is another, and perhaps more efficient, way of obtaining this measure \cite{ciesinski1}. Consider the following sets:\\
	$S_{s}=SAT(\Psi)$;\\
	$S_{f}=(s\in S:s\notin SAT(\Phi) \wedge s\notin SAT(\Psi))$;\\
	$S_{i}=(s\in S:s\in SAT(\Phi)\wedge s\notin SAT(\Psi))$\\
	$U_{0} = S_{f}$ $\cup$ $(s\in S_{i}:$there exists no path in $S_{i}$ from $s$ to $s^{\prime} \in S_{s})$\\
	$U_{1} = S_{i}$ $\cup$ $(s\in S_{i}:$the measure of reaching $s^{\prime}\in S_{s}$ through $S_{i}$ from $s$ is 1\\
	$U_{?} = S\setminus(U_{0}\cup U_{1})$.\\
	Sets $U_{0}$ and $U_{1}$ can conveniently be found. The preliminary step is to make all $S_{f}\cup S_{s}$, $(\lnot\Phi\vee\Psi)$, -states absorbing. Set $U_{0}$ is a set of states from which the $\Psi$-states are not reachable. For this tried first to determine the states from which $\Psi$ states are reachable. This is achieved by starting from $S_{s}$ and performing a backward search until no more states are found. This gives $S\setminus U_{0}$ hence $U_{0}$ is obtained. Set $U_{1}$ is a set of states from which $U_{0}$-states should not be reachable since $\Psi$ states should always be reachable. Hence to determine $U_{1}$ first find all the states from which $U_{0}$ is reachable. This is performed by a backward search starting from $U_{0}$. This search results in $S\setminus U_{1}$ hence $U_{1}$ is obtained. Given these sets the desired probabilities are determined by the solution of the following linear equation system:
	\begin{eqnarray*}
	x_{s}
	&=&\ \left\{
	\begin{array}{l}
	0 \text{, if } s\in U_{0}\\
	1 \text{, if } s\in U_{1}\\
	\sum\limits_{s^{\prime}\in U_{?}}P(s,s^{\prime})\cdot x_{s^{\prime}}+\sum\limits_{s^{\prime}\in U_{1}}P(s,s^{\prime}) \text{, if } s\in U_{?} \text{.}
	\end{array}
	\right.
	\end{eqnarray*}
	This system can be solved by well-known iterative methods such as Jacobi method.
	\subsubsection{Bounded $\mathcal{U}$ntil}
	The procedure for model checking the bounded $\mathcal{U}$ntil operator is to first make some of the states absorbing (as a consequence of Theorem 2 in \cite{baier1}). \\
	1. Make all $(\lnot\Phi\vee\Psi)$-states absorbing. \\
	2. Uniformize the CTMC. \\
	3. Obtain the state probabilities.
	\begin{equation*}
	P=I+\frac{R-diag(E)}{\Lambda}
	\end{equation*} 
	Subsequently the state probabilities, for starting state $s\in S$, are determined:
	\begin{equation*}
	\underline{p}_{t}=\underline{p}(0)\cdot\sum\limits_{i=0}^{\infty }\frac{e^{-\Lambda t}(\Lambda t)^{i}}{i!}\cdot P^{i}.
	\end{equation*}
	\begin{equation*}
	Prob^{\mathcal{M}}(s,\Phi\mathcal{U}^{(0,t)}\Psi)=\sum\limits_{s\in Sat(\Psi)}\underline{p}_{t}(s).
	\end{equation*}
	An efficient variant for this algorithm is provided in \cite{katoen1} using which the state-probabilities are calculated for all states is:
	\begin{equation*}	
	\underline{p}_{t}=\sum\limits_{i=0}^{\infty }\psi(i, \Lambda\cdot t)\cdot \underline{p}_{i}
	\end{equation*}
	where $\underline{p}_{0} = 1_{\Psi}$ and $\underline{p}_{i}=P\cdot\underline{p}_{i-1}$ for $i=1\cdots$ and
	\begin{equation*}
	Prob^{\mathcal{M}}(s,\Phi\mathcal{U}^{(0,t)}\Psi)=\underline{p}_{t}(s), s\in S.
	\end{equation*}
	The following improvement has been incorporated in ETMCC v2.
	\begin{itemize}
		\item: Performing an analysis similar to that for Unbounded $\mathcal{U}$ntil and then making all the $U_{0}$ state absorbing too. This potentially reduces the state space.
	\end{itemize}
	Further improvement is possible:
	\begin{itemize}
		\item: Performing an analysis similar to that for Unbounded $\mathcal{U}$ntil and computing $\mathcal{P}_{>p}(\Phi \mathcal{U} \Psi)$. Subsequently all the $U_{0}$ states are made absorbing too and transient analysis is carried out only if $\mathcal{P}_{>p}(\Phi \mathcal{U} \Psi)$ is satisfied. However, the solution of the unbounded $\mathcal{U}$ntil is an expensive operation as well and hence this improvement was not incorporated. 
	\end{itemize}
	
	\subsubsection{Interval $\mathcal{U}$ntil}
	The procedure for model checking the interval $\mathcal{U}$ntil operator, where $I=[t_1,t_2]$, is to first make some of the states absorbing (as a consequence of Theorem 3 in \cite{baier1} and the efficient variant in \cite{katoen1}).
	\begin{itemize}
		\item:  First make all (!EU and AU states absorbing to get $R_1$: then find $P_1 = (R_1-diag(E))/lambda$)
	\begin{equation*}	
	\underline{p}_{t_2-t_1}^{\prime}=\sum\limits_{i=0}^{\infty }\psi(i, \Lambda\cdot (t_2-t_1))\cdot \underline{p}_{i}^{\prime}
	\end{equation*}
	where $\underline{p}_{0}^{\prime} = 1_{AU}$ and $\underline{p}_{i}^{\prime}=P_1\cdot\underline{p}_{i-1}^{\prime}$ for $i=1\cdots$
		\item: Now make all $\Phi$-states absorbing to get $R_2$. Then find $P_2 = (R_2-diag(E))/lambda$)
	\begin{equation*}	
	\underline{p}_{t}=\sum\limits_{i=0}^{\infty }\psi(i, \Lambda\cdot t_1)\cdot \underline{p}_{i}
	\end{equation*}
	where $\underline{p}_{0} = \underline{p}_{t_2-t_1}^{\prime}$ and $\underline{p}_{i}=P_2\cdot\underline{p}_{i-1}$ for $i=1\cdots$ and
	\begin{equation*}
	Prob^{\mathcal{M}}(s,\Phi\mathcal{U}^{(t_1,t_2)}\Psi)= \underline{p}_{t}(s), s\in S.
	\end{equation*}
	\end{itemize}
\subsubsection{Steady State Detection for bounded until \textit{\{Ivan\}}}
\subsubsection{ODE solutions \textit{\{Maneesh\}}}
	Krylov subspaces, etc... ExpoKit.
\subsubsection{Estimates for bounded until \textit{\{Ivan\}}}
	
\subsection{Path Formulas - CSRL \textit{\{Maneesh\}}}

\section{Experimental results }
	Compare efficiency of ETMCC v2.0 with ETMCC v1.0, Prizm without BDDS and GreatSPN (for CSL).

\subsection{Steady state analysis \textit{\{Ivan\}}}
	The steady state operator.

\subsection{Transient analysis \textit{\{Maneesh\}}}
	The until operator.

\section{Conclusions \textit{\{???\}}}

\begin{thebibliography}{5}

\bibitem{baier1} C. Baier, B.R. Haverkort and H. Hermanns and J.-P. Katoen.
\newblock \emph{Model-Checking Algorithms for Continuous-Time Markov Chains}.
\newblock IEEE Transactions on Software Engineering, Vol. 29, Issue: 6, pp. 524-541, 2003.

\bibitem{ciesinski1} F. Ciesinski, M. Gr\"o\ss er.
\newblock \emph{On Probabilistic Computation Tree Logic}.
\newblock Lecture Notes in Computer Science, Vol. 2925, Springer, pp. 147-188, 2004.

\bibitem{ejim1} E.J. Im.
\newblock \emph{Optimizing the Performance of Sparse Matrix-Vector Multiplication}.
\newblock Ph.D. Thesis, University of California, Berkeley, 2000.
	
\bibitem{fox1} B.L. Fox and P.W. Glynn.
\newblock \emph{Computing Poisson Probabilities}.
\newblock Comm. ACM, Vol. 31, No. 4, pp. 440-445, 1988.

\bibitem{haverkort1} B. Haverkort, H. Hermanns and J.-P. Katoen
\newblock \emph{On the use of model checking techniques for dependability evaluation}.
\newblock SRDS'00, IEEE CS Press, pp. 228-237, 2000.

\bibitem{katoen1} J.-P Katoen, M.Z. Kwiatowska, G. Norman, D.A. Parker.
\newblock \emph{Faster and symbolic CTMC model checking}.
\newblock Lecture Notes in Computer Science, Vol. 2165, Springer, Aachen, Germany, pp. 23-38, 2001.
 
\bibitem{nuutila1} E. Nuutila and E. Soisalon-Soininen.
\newblock \emph{On Finding the Strongly Connected Components in a Directed Graph}.
\newblock Information Processing Letters, Volume~49:9-14, 1993.

\bibitem{tarjan1} R. E. Tarjan.
\newblock \emph{Depth first search and linear graph algorithms}.
\newblock SIAM Journal of Computing, Volume~1(2):146-160, June 1972

\bibitem{xie1} Aiguo Xie and Peter A. Beerel
\newblock \emph{Efficient State Classification of Finite State Markov Chains}.

\end{thebibliography}

\newpage
\appendix
  \renewcommand{\theequation}{A-\arabic{equation}}
  % redefine the command that creates the equation no.
  \setcounter{equation}{0}  % reset counter 
  \section*{APPENDIX}  % use *-form to suppress numbering

\section{Grammar for logic \textit{\{PCTL/PRCTL/CSL/CSRL\}}}
In ETMCC v.2 a unified parser for the logics PCTL/PRCTL/CSL/CSRL has been generated using the
tool YACC. The terminal symbols and their names used in YACC are shown in Table \ref{Tbl:lex}. The
YACC specification of the parser is presented in Table \ref{Tbl:parser}. Note that non-terminals are
in lower case and terminal symbols are in upper case and some details about implementation in YACC
are omitted for convenience.

\input{lex}
\input{parser}

\section{ETMCC v2.0 manual \textit{\{???\}}}

\subsection{ETMCC v2.0 inputs \textit{\{???\}}}
	The .tra, .lab, .rew file examples, ETMCC v2.0 parameters.

\subsection{ETMCC v2.0 commands \& formulas \textit{\{???\}}}
	help, quit, print, set, and formulas with examples.
	
\section{CTMC Example \textit{\{???\}}}
	Example of a CTMC with results.

\end{document}          
